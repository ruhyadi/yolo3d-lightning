{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YOLO3D: 3D Object Detection with YOLO","text":""},{"location":"#cautions","title":"\u26a0\ufe0f\u00a0\u00a0Cautions","text":"<p>This repository currently under development</p>"},{"location":"#demo","title":"\ud83d\udcfc\u00a0\u00a0Demo","text":"![demo](./assets/demo.gif)"},{"location":"#introduction","title":"\ud83d\udccc\u00a0\u00a0Introduction","text":"<p>Unofficial implementation of Mousavian et al. in their paper 3D Bounding Box Estimation Using Deep Learning and Geometry. YOLO3D uses a different approach, as the detector uses YOLOv5 which previously used Faster-RCNN, and Regressor uses ResNet18/VGG11 which was previously VGG19.</p>"},{"location":"#quickstart","title":"\ud83d\ude80\u00a0\u00a0Quickstart","text":"<p>We use hydra as the config manager; if you are unfamiliar with hydra, you can visit the official website or see the tutorial on this web.</p>"},{"location":"#inference","title":"\ud83c\udf7f\u00a0\u00a0Inference","text":"<p>You can use pretrained weight from Release, you can download it using script <code>get_weights.py</code>: <pre><code># download pretrained model\npython script/get_weights.py \\\n--tag v0.1 \\\n--dir ./weights\n</code></pre> Inference with <code>inference.py</code>: <pre><code>python inference.py \\\nsource_dir=\"./data/demo/images\" \\\ndetector.model_path=\"./weights/detector_yolov5s.pt\" \\\nregressor_weights=\"./weights/regressor_resnet18.pt\"\n</code></pre></p>"},{"location":"#training","title":"\u2694\ufe0f\u00a0\u00a0Training","text":"<p>There are two models that will be trained here: detector and regressor. For now, the detector model that can be used is only YOLOv5, while the regressor model can use all models supported by Torchvision.</p>"},{"location":"#training-yolov5-detector","title":"\ud83e\udded\u00a0\u00a0Training YOLOv5 Detector","text":"<p>The first step is to change the <code>label_2</code> format from KITTI to YOLO. You can use the following <code>src/kitti_to_yolo.py</code>.</p> <pre><code>cd yolo3d-lightning/src\npython kitti_to_yolo.py \\\n--dataset_path ../data/KITTI/training/\n  --classes [\"car\", \"van\", \"truck\", \"pedestrian\", \"cyclist\"]\n--img_width 1224\n--img_height 370\n</code></pre> <p>The next step is to follow the wiki provided by ultralytics. Note: readme will updated in future.</p>"},{"location":"#training-regessor","title":"\ud83e\ude80\u00a0\u00a0Training Regessor","text":"<p>Selanjutnya, kamu dapat melakukan training model regressor. Model regressor yang dapat dipakai bisa mengacu pada yang tersedia di <code>torchvision</code>, atau kamu bisa mengkustomnya sendiri. </p> <p>Langkah pertama adalah membuat train dan validation sets. Kamu dapat menggunakan <code>script/generate_sets.py</code>:</p> <pre><code>cd yolo3d-lightning/script\npython generate_sets.py \\\n--images_path ../data/KITTI/training/images # or image_2\n--dump_dir ../data/KITTI/training\n  --postfix _80\n  --train_size 0.8\n</code></pre> <p>Pada langkah selanjutnya, kita hanya akan menggunakan model yang ada di <code>torchvision</code> saja. Langkah termudah adalah dengan mengubah configurasi di <code>configs.model.regressor.yaml</code>, seperti di bawah:</p> <pre><code>_target_: src.models.regressor.RegressorModel\nnet:\n_target_: src.models.components.base.RegressorNet\nbackbone:\n_target_: torchvision.models.resnet18 # edit this\npretrained: True # maybe this too\nbins: 2\nlr: 0.001\nmomentum: 0.9\nw: 0.4\nalpha: 0.6\n</code></pre> <p>Langkah selanjutnya adalah dengan membuat konfigurasi experiment pada <code>configs/experiment/your_exp.yaml</code>. Jika bingung, kamu dapat mengacu pada <code>configs/experiment/demo.yaml</code>. </p> <p>Setelah konfigurasi experiment dibuat. Kamu dapat dengan mudah menjalankan perintah <code>train.py</code>, seperti berikut:</p> <pre><code>cd yolo3d-lightning\npython train.py \\\nexperiment=demo\n</code></pre>"},{"location":"#acknowledgement","title":"\u2764\ufe0f\u00a0\u00a0Acknowledgement","text":"<ul> <li>YOLOv5 by Ultralytics</li> <li>skhadem/3D-BoundingBox</li> <li>Mousavian et al. <pre><code>@misc{mousavian20173d,\n      title={3D Bounding Box Estimation Using Deep Learning and Geometry}, \n      author={Arsalan Mousavian and Dragomir Anguelov and John Flynn and Jana Kosecka},\n      year={2017},\n      eprint={1612.00496},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n</code></pre></li> </ul>"},{"location":"command/","title":"Quick Command","text":""},{"location":"command/#train-regressor-model","title":"Train Regressor Model","text":"<ul> <li> <p>Train original <pre><code>python src/train.py\n</code></pre></p> </li> <li> <p>With experiment <pre><code>python src/train.py \\\nexperiment=sample\n</code></pre></p> </li> </ul>"},{"location":"command/#train-detector-model","title":"Train Detector Model","text":""},{"location":"command/#yolov5","title":"Yolov5","text":"<ul> <li> <p>Multi GPU Training <pre><code>cd yolov5\npython -m torch.distributed.launch \\\n--nproc_per_node 4 train.py \\\n--epochs 10 \\\n--batch 64 \\\n--data ../configs/detector/yolov5_kitti.yaml \\\n--weights yolov5s.pt \\\n--device 0,1,2,3\n</code></pre></p> </li> <li> <p>Single GPU Training <pre><code>cd yolov5\npython train.py \\\n--data ../configs/detector/yolov5_kitti.yaml \\\n--weights yolov5s.pt \\\n--img 640 </code></pre></p> </li> </ul>"},{"location":"command/#hyperparameter-tuning-with-hydra","title":"Hyperparameter Tuning with Hydra","text":"<pre><code>python src/train.py -m \\\nhparams_search=regressor_optuna \\\nexperiment=sample_optuna\n</code></pre>"}]}